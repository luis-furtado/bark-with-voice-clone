Search.setIndex({"docnames": ["bark", "index", "modules"], "filenames": ["bark.rst", "index.rst", "modules.rst"], "titles": ["bark package", "Welcome to Bark\u2019s documentation!", "bark"], "terms": {"generate_audio": [0, 2], "text": 0, "str": 0, "history_prompt": 0, "dict": 0, "none": 0, "text_temp": 0, "float": 0, "0": 0, "7": 0, "waveform_temp": 0, "silent": 0, "bool": 0, "fals": 0, "output_ful": 0, "audio": 0, "arrai": 0, "from": 0, "input": 0, "paramet": 0, "turn": 0, "histori": 0, "choic": 0, "clone": 0, "temperatur": 0, "1": 0, "more": 0, "divers": 0, "conserv": 0, "disabl": 0, "progress": 0, "bar": 0, "return": 0, "full": 0, "us": 0, "prompt": 0, "numpi": 0, "sampl": 0, "frequenc": 0, "24khz": 0, "save_as_prompt": [0, 2], "filepath": 0, "full_gener": 0, "semantic_to_waveform": [0, 2], "semantic_token": 0, "ndarrai": 0, "temp": 0, "semant": 0, "token": 0, "output": 0, "text_to_semant": [0, 2], "fed": 0, "class": 0, "inferencecontext": [0, 2], "benchmark": 0, "base": 0, "object": 0, "autocast": [0, 2], "clean_model": [0, 2], "model_kei": 0, "codec_decod": [0, 2], "fine_token": 0, "quantiz": 0, "code": 0, "encodec": 0, "generate_coars": [0, 2], "x_semant": 0, "top_k": 0, "top_p": 0, "max_coarse_histori": 0, "630": 0, "sliding_window_len": 0, "60": 0, "use_kv_cach": 0, "coars": 0, "generate_fin": [0, 2], "x_coarse_gen": 0, "5": 0, "true": 0, "generate_text_semant": [0, 2], "min_eos_p": 0, "2": 0, "max_gen_duration_": 0, "allow_early_stop": 0, "load_codec_model": [0, 2], "use_gpu": 0, "force_reload": 0, "load_model": [0, 2], "use_smal": 0, "model_typ": 0, "preload_model": [0, 2], "text_use_gpu": 0, "text_use_smal": 0, "coarse_use_gpu": 0, "coarse_use_smal": 0, "fine_use_gpu": 0, "fine_use_smal": 0, "codec_use_gpu": 0, "load": 0, "all": 0, "necessari": 0, "pipelin": 0, "much": 0, "thi": 0, "i": 0, "adapt": 0, "andrej": 0, "karpathi": 0, "": 0, "nanogpt": 0, "http": 0, "github": 0, "com": 0, "block": [0, 2], "config": 0, "layer_idx": 0, "forward": [0, 2], "x": 0, "past_kv": 0, "use_cach": 0, "defin": 0, "comput": 0, "perform": 0, "everi": 0, "call": 0, "should": 0, "overridden": 0, "subclass": 0, "although": 0, "recip": 0, "pass": 0, "need": 0, "within": 0, "function": 0, "one": 0, "instanc": 0, "afterward": 0, "instead": 0, "sinc": 0, "former": 0, "take": 0, "care": 0, "run": 0, "regist": 0, "hook": 0, "while": 0, "latter": 0, "ignor": 0, "them": 0, "causalselfattent": [0, 2], "gpt": [0, 2], "idx": 0, "merge_context": 0, "position_id": 0, "get_num_param": [0, 2], "non_embed": 0, "number": 0, "For": 0, "non": 0, "embed": 0, "count": 0, "default": 0, "posit": 0, "get": 0, "subtract": 0, "The": 0, "would": 0, "too": 0, "except": 0, "due": 0, "share": 0, "param": 0, "ar": 0, "actual": 0, "weight": 0, "final": 0, "layer": 0, "so": 0, "we": 0, "includ": 0, "gptconfig": [0, 2], "block_siz": [0, 2], "int": 0, "1024": 0, "input_vocab_s": [0, 2], "10048": 0, "output_vocab_s": [0, 2], "n_layer": [0, 2], "12": 0, "n_head": [0, 2], "n_embd": [0, 2], "768": 0, "dropout": [0, 2], "bia": [0, 2], "layernorm": [0, 2], "ndim": 0, "an": 0, "option": 0, "pytorch": 0, "doesn": 0, "t": 0, "support": 0, "simpli": 0, "mlp": [0, 2], "fineblock": [0, 2], "finegpt": [0, 2], "pred_idx": 0, "finegptconfig": [0, 2], "n_codes_tot": [0, 2], "8": 0, "n_codes_given": [0, 2], "noncausalselfattent": [0, 2], "index": 1, "modul": [1, 2], "search": 1, "page": 1, "packag": 2, "submodul": 2, "api": 2, "gener": 2, "model": 2, "model_fin": 2, "content": 2}, "objects": {"": [[0, 0, 0, "-", "bark"]], "bark": [[0, 0, 0, "-", "api"], [0, 0, 0, "-", "generation"], [0, 0, 0, "-", "model"], [0, 0, 0, "-", "model_fine"]], "bark.api": [[0, 1, 1, "", "generate_audio"], [0, 1, 1, "", "save_as_prompt"], [0, 1, 1, "", "semantic_to_waveform"], [0, 1, 1, "", "text_to_semantic"]], "bark.generation": [[0, 2, 1, "", "InferenceContext"], [0, 1, 1, "", "autocast"], [0, 1, 1, "", "clean_models"], [0, 1, 1, "", "codec_decode"], [0, 1, 1, "", "generate_coarse"], [0, 1, 1, "", "generate_fine"], [0, 1, 1, "", "generate_text_semantic"], [0, 1, 1, "", "load_codec_model"], [0, 1, 1, "", "load_model"], [0, 1, 1, "", "preload_models"]], "bark.model": [[0, 2, 1, "", "Block"], [0, 2, 1, "", "CausalSelfAttention"], [0, 2, 1, "", "GPT"], [0, 2, 1, "", "GPTConfig"], [0, 2, 1, "", "LayerNorm"], [0, 2, 1, "", "MLP"]], "bark.model.Block": [[0, 3, 1, "", "forward"]], "bark.model.CausalSelfAttention": [[0, 3, 1, "", "forward"]], "bark.model.GPT": [[0, 3, 1, "", "forward"], [0, 3, 1, "", "get_num_params"]], "bark.model.GPTConfig": [[0, 4, 1, "", "bias"], [0, 4, 1, "", "block_size"], [0, 4, 1, "", "dropout"], [0, 4, 1, "", "input_vocab_size"], [0, 4, 1, "", "n_embd"], [0, 4, 1, "", "n_head"], [0, 4, 1, "", "n_layer"], [0, 4, 1, "", "output_vocab_size"]], "bark.model.LayerNorm": [[0, 3, 1, "", "forward"]], "bark.model.MLP": [[0, 3, 1, "", "forward"]], "bark.model_fine": [[0, 2, 1, "", "FineBlock"], [0, 2, 1, "", "FineGPT"], [0, 2, 1, "", "FineGPTConfig"], [0, 2, 1, "", "NonCausalSelfAttention"]], "bark.model_fine.FineBlock": [[0, 3, 1, "", "forward"]], "bark.model_fine.FineGPT": [[0, 3, 1, "", "forward"], [0, 3, 1, "", "get_num_params"]], "bark.model_fine.FineGPTConfig": [[0, 4, 1, "", "n_codes_given"], [0, 4, 1, "", "n_codes_total"]], "bark.model_fine.NonCausalSelfAttention": [[0, 3, 1, "", "forward"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:method", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"bark": [0, 1, 2], "packag": 0, "submodul": 0, "api": 0, "modul": 0, "gener": 0, "model": 0, "model_fin": 0, "content": 0, "welcom": 1, "": 1, "document": 1, "indic": 1, "tabl": 1}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"bark package": [[0, "bark-package"]], "Submodules": [[0, "submodules"]], "bark.api module": [[0, "module-bark.api"]], "bark.generation module": [[0, "module-bark.generation"]], "bark.model module": [[0, "module-bark.model"]], "bark.model_fine module": [[0, "module-bark.model_fine"]], "Module contents": [[0, "module-bark"]], "Welcome to Bark\u2019s documentation!": [[1, "welcome-to-bark-s-documentation"]], "Indices and tables": [[1, "indices-and-tables"]], "bark": [[2, "bark"]]}, "indexentries": {"block (class in bark.model)": [[0, "bark.model.Block"]], "causalselfattention (class in bark.model)": [[0, "bark.model.CausalSelfAttention"]], "fineblock (class in bark.model_fine)": [[0, "bark.model_fine.FineBlock"]], "finegpt (class in bark.model_fine)": [[0, "bark.model_fine.FineGPT"]], "finegptconfig (class in bark.model_fine)": [[0, "bark.model_fine.FineGPTConfig"]], "gpt (class in bark.model)": [[0, "bark.model.GPT"]], "gptconfig (class in bark.model)": [[0, "bark.model.GPTConfig"]], "inferencecontext (class in bark.generation)": [[0, "bark.generation.InferenceContext"]], "layernorm (class in bark.model)": [[0, "bark.model.LayerNorm"]], "mlp (class in bark.model)": [[0, "bark.model.MLP"]], "noncausalselfattention (class in bark.model_fine)": [[0, "bark.model_fine.NonCausalSelfAttention"]], "autocast() (in module bark.generation)": [[0, "bark.generation.autocast"]], "bark": [[0, "module-bark"]], "bark.api": [[0, "module-bark.api"]], "bark.generation": [[0, "module-bark.generation"]], "bark.model": [[0, "module-bark.model"]], "bark.model_fine": [[0, "module-bark.model_fine"]], "bias (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.bias"]], "block_size (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.block_size"]], "clean_models() (in module bark.generation)": [[0, "bark.generation.clean_models"]], "codec_decode() (in module bark.generation)": [[0, "bark.generation.codec_decode"]], "dropout (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.dropout"]], "forward() (bark.model.block method)": [[0, "bark.model.Block.forward"]], "forward() (bark.model.causalselfattention method)": [[0, "bark.model.CausalSelfAttention.forward"]], "forward() (bark.model.gpt method)": [[0, "bark.model.GPT.forward"]], "forward() (bark.model.layernorm method)": [[0, "bark.model.LayerNorm.forward"]], "forward() (bark.model.mlp method)": [[0, "bark.model.MLP.forward"]], "forward() (bark.model_fine.fineblock method)": [[0, "bark.model_fine.FineBlock.forward"]], "forward() (bark.model_fine.finegpt method)": [[0, "bark.model_fine.FineGPT.forward"]], "forward() (bark.model_fine.noncausalselfattention method)": [[0, "bark.model_fine.NonCausalSelfAttention.forward"]], "generate_audio() (in module bark.api)": [[0, "bark.api.generate_audio"]], "generate_coarse() (in module bark.generation)": [[0, "bark.generation.generate_coarse"]], "generate_fine() (in module bark.generation)": [[0, "bark.generation.generate_fine"]], "generate_text_semantic() (in module bark.generation)": [[0, "bark.generation.generate_text_semantic"]], "get_num_params() (bark.model.gpt method)": [[0, "bark.model.GPT.get_num_params"]], "get_num_params() (bark.model_fine.finegpt method)": [[0, "bark.model_fine.FineGPT.get_num_params"]], "input_vocab_size (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.input_vocab_size"]], "load_codec_model() (in module bark.generation)": [[0, "bark.generation.load_codec_model"]], "load_model() (in module bark.generation)": [[0, "bark.generation.load_model"]], "module": [[0, "module-bark"], [0, "module-bark.api"], [0, "module-bark.generation"], [0, "module-bark.model"], [0, "module-bark.model_fine"]], "n_codes_given (bark.model_fine.finegptconfig attribute)": [[0, "bark.model_fine.FineGPTConfig.n_codes_given"]], "n_codes_total (bark.model_fine.finegptconfig attribute)": [[0, "bark.model_fine.FineGPTConfig.n_codes_total"]], "n_embd (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.n_embd"]], "n_head (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.n_head"]], "n_layer (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.n_layer"]], "output_vocab_size (bark.model.gptconfig attribute)": [[0, "bark.model.GPTConfig.output_vocab_size"]], "preload_models() (in module bark.generation)": [[0, "bark.generation.preload_models"]], "save_as_prompt() (in module bark.api)": [[0, "bark.api.save_as_prompt"]], "semantic_to_waveform() (in module bark.api)": [[0, "bark.api.semantic_to_waveform"]], "text_to_semantic() (in module bark.api)": [[0, "bark.api.text_to_semantic"]]}})